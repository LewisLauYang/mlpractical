
@Book{deeplearning2016,
	series = {Adaptive computation and machine learning},
	publisher = {The MIT Press},
	isbn = {0262035618},
	year = {2016},
	title = {Deep learning},
	language = {eng},
	address = {Cambridge, Massachusetts},
	author = {Goodfellow, Ian},
	keywords = {Machine learning},
}

@Misc{CS231n,
	howpublished = {\url{http://cs231n.github.io/convolutional-networks/}},
	title = {CS231n Convolutional Neural Networks for Visual Recognition},
	author = {CS231n}
}

@article{DBLP:journals/corr/YuK15,
	author    = {Fisher Yu and
	Vladlen Koltun},
	title     = {Multi-Scale Context Aggregation by Dilated Convolutions},
	journal   = {CoRR},
	volume    = {abs/1511.07122},
	year      = {2015},
	url       = {http://arxiv.org/abs/1511.07122},
	archivePrefix = {arXiv},
	eprint    = {1511.07122},
	timestamp = {Mon, 13 Aug 2018 16:49:01 +0200},
	biburl    = {https://dblp.org/rec/bib/journals/corr/YuK15},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{LecunY.1998Glat,
	issn = {0018-9219},
	abstract = {Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional neural networks, which are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition, and language modeling. A new learning paradigm, called graph transformer networks (GTN), allows such multimodule systems to be trained globally using gradient-based methods so as to minimize an overall performance measure. Two systems for online handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of graph transformer networks. A graph transformer network for reading a bank cheque is also described. It uses convolutional neural network character recognizers combined with global training techniques to provide record accuracy on business and personal cheques. It is deployed commercially and reads several million cheques per day.},
	journal = {Proceedings of the IEEE},
	pages = {2278--2324},
	volume = {86},
	publisher = {IEEE},
	number = {11},
	year = {1998},
	title = {Gradient-based learning applied to document recognition},
	language = {eng},
	address = {USA},
	author = {Lecun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},
	keywords = {General Topics for Engineers ; Engineering Profession},
}

@article{JiaYangqing2014LSIR,
	abstract = {I present my work towards learning a better computer vision system that learns and generalizes object categories better, and behaves in ways closer to what human behave. Specifically, I focus on two key components of such a system: learning better features, and revisiting existing problem statements. For the first component, I propose and analyze novel receptive field learning and dictionary learning methods, mathematically justified by the \nystrom sampling theory, that learn more compact and effective features for object recognition tasks. For the second component, I propose to combine otherwise independently developed computer vision and cognitive science studies, and present the first large-scale system that allows computers to learn and generalize closer to what a human learner will do. I also provide a large-scale human behavior database, which will hopefully enable further research along this research direction.Following the recent success of convolutional neural networks, I present and release a well-engineered framework for general deep learning research, and provide an extensive analysis on the generality of deep features learned from the state-of-the-art CNN pipeline: whether they serve as a general-purpose visual descriptor that could be adopted in various applications, and future research directions made possible by such general features.},
	publisher = {eScholarship},
	year = {2014},
	title = {Learning Semantic Image Representations at a Large Scale},
	address = {University of California},
	author = {Jia, Yangqing},
	keywords = {Computer science},
	url = {http://www.escholarship.org/uc/item/64c2v6sn},
}



@inproceedings{langley00,
 author    = {P. Langley},
 title     = {Crafting Papers on Machine Learning},
 year      = {2000},
 pages     = {1207--1216},
 editor    = {Pat Langley},
 booktitle     = {Proceedings of the 17th International Conference
              on Machine Learning (ICML 2000)},
 address   = {Stanford, CA},
 publisher = {Morgan Kaufmann}
}

@TechReport{mitchell80,
  author = 	 "T. M. Mitchell",
  title = 	 "The Need for Biases in Learning Generalizations",
  institution =  "Computer Science Department, Rutgers University",
  year = 	 "1980",
  address =	 "New Brunswick, MA",
}

@phdthesis{kearns89,
  author = {M. J. Kearns},
  title =  {Computational Complexity of Machine Learning},
  school = {Department of Computer Science, Harvard University},
  year =   {1989}
}

@Book{MachineLearningI,
  editor = 	 "R. S. Michalski and J. G. Carbonell and T.
		  M. Mitchell",
  title = 	 "Machine Learning: An Artificial Intelligence
		  Approach, Vol. I",
  publisher = 	 "Tioga",
  year = 	 "1983",
  address =	 "Palo Alto, CA"
}



@Book{DudaHart2nd,
  author =       "R. O. Duda and P. E. Hart and D. G. Stork",
  title =        "Pattern Classification",
  publisher =    "John Wiley and Sons",
  edition =      "2nd",
  year =         "2000"
}

@misc{anonymous,
  title= {Suppressed for Anonymity},
  author= {Author, N. N.},
  year= {2011},
}

@InCollection{Newell81,
  author =       "A. Newell and P. S. Rosenbloom",
  title =        "Mechanisms of Skill Acquisition and the Law of
                  Practice", 
  booktitle =    "Cognitive Skills and Their Acquisition",
  pages =        "1--51",
  publisher =    "Lawrence Erlbaum Associates, Inc.",
  year =         "1981",
  editor =       "J. R. Anderson",
  chapter =      "1",
  address =      "Hillsdale, NJ"
}


@Article{Samuel59,
  author = 	 "A. L. Samuel",
  title = 	 "Some Studies in Machine Learning Using the Game of
		  Checkers",
  journal =	 "IBM Journal of Research and Development",
  year =	 "1959",
  volume =	 "3",
  number =	 "3",
  pages =	 "211--229"
}

@article{loshchilov2018fixing,
  title = {Fixing weight decay regularization in {Adam}},
  author = {Loshchilov, Ilya and Hutter, Frank},
  journal={arXiv preprint arXiv:1711.05101},
  year={2017},
  url = {https://arxiv.org/abs/1711.05101}
}